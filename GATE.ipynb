{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATE(nn.Module):\n",
    "    def __init__(self,hidden_dims,A,X,S,R,lambda_=0.05):\n",
    "        super().__init__()\n",
    "        self.lambda_ = lambda_\n",
    "        self.n_layers = len(hidden_dims)-1\n",
    "        self.W,self.v = self.define_weights(hidden_dims)\n",
    "        self.C={}\n",
    "        self.threshold = 0.01\n",
    "        self.A = A\n",
    "        self.X = X\n",
    "        self.S = S\n",
    "        self.R = R\n",
    "        self.apply(self._init_weights)\n",
    "    #前向传播\n",
    "    def forward(self,A,X,R,S):\n",
    "\n",
    "        #编码\n",
    "        H = X\n",
    "        for layer in range(self.n_layers):\n",
    "            H = self.encoder(A, H, layer)\n",
    "        #最终节点表征\n",
    "        self.H = H\n",
    "\n",
    "        #解码\n",
    "        for layer in range(self.n_layers-1,-1,-1):\n",
    "            H = self.decoder(H,layer)\n",
    "        X_ = H\n",
    "\n",
    "        #节点得重构损失\n",
    "        features_loss = torch.sqrt(torch.sum((X-X_)**2))\n",
    "\n",
    "        #图结构得重构损失\n",
    "        S_emb = self.H[S]\n",
    "        R_emb = self.H[R]\n",
    "        structure_loss = -torch.log(torch.sigmoid(torch.sum(S_emb*R_emb,dim=-1))).sum()\n",
    "\n",
    "        #总损失\n",
    "        self.loss = features_loss + self.lambda_*structure_loss\n",
    "\n",
    "        return self.loss,self.H,self.C\n",
    "    def encoder(self,A,H,layer):\n",
    "        H = nn.LeakyReLU(0.2)(H)\n",
    "        H = torch.matmul(H,self.W[layer].weight.t())\n",
    "        self.C[layer]= self.graph_attention_layer(A,H,self.v[layer],layer,self.threshold)\n",
    "        return torch.matmul(self.C[layer],H)\n",
    "    #解码器\n",
    "    def decoder(self,H,layer):\n",
    "        H = torch.matmul(H,self.W[layer].weight)\n",
    "        H = nn.BatchNorm1d(H.size(1))(H)   #添加 BatchNorm\n",
    "        H = nn.ReLU()(H)\n",
    "        return torch.matmul(self.C[layer],H)\n",
    "    \n",
    "    def define_weights(self,hidden_dims):\n",
    "        W = nn.ModuleList(nn.Linear(hidden_dims[i],hidden_dims[i+1])for i in range(self.n_layers))\n",
    "        Ws_att = nn.ModuleList([nn.ModuleList([nn.Linear(hidden_dims[i+1],1,bias=False),nn.Linear(hidden_dims[i+1],1,bias=False)])for i in range(self.n_layers)])\n",
    "        return W,Ws_att\n",
    "    def graph_attention_layer(self,A,M,v,layer,threshold):\n",
    "        '''\n",
    "        全连接图注意力层（带阈值剪枝）\n",
    "        参数：\n",
    "        M:节点特征矩阵N,d\n",
    "        v:注意力参数列表，包含两个可学习向量v1,v2每个形状d,1\n",
    "        layer:层编号\n",
    "        threshold:注意力权重剪枝阈值(默认0.1)\n",
    "        '''\n",
    "        #启用异常检测，监控反向传播\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            #计算全连接注意力分数\n",
    "            f1 = torch.matmul(M,v[0].weight.t())\n",
    "            f2 = torch.matmul(M,v[1].weight.t())\n",
    "\n",
    "            #生成全连接分数矩阵N,N\n",
    "            logits = f1 + f2.T\n",
    "            logits = logits / torch.max(torch.abs(logits))   #归一化\n",
    "            #激活函数\n",
    "            unnormalized_attentions = torch.exp(logits)\n",
    "            \n",
    "            #行方向归一化\n",
    "            attentions = F.softmax(unnormalized_attentions,dim=1)\n",
    "         \n",
    "            #阈值剪枝\n",
    "            attentions = F.dropout(attentions,p=0.2,training=self.training)\n",
    "            return attentions\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.ModuleList):   #针对注意力参数的特殊初始化\n",
    "            for sub_module in m:\n",
    "                if isinstance(sub_module, nn.Linear):\n",
    "                    nn.init.normal_(sub_module.weight, mean=0, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#数据归一化\n",
    "df = pd.read_excel('standardized_file.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    df[column] = (df[column]-df[column].mean())/df[column].std()\n",
    "df = df.drop(0,axis=1)\n",
    "data_3d = df.values.reshape(296,22,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cities = 292\n",
    "num_nodes = 22\n",
    "num_features = 5\n",
    "hidden_dims = [5,16,32,16,5]\n",
    "lambda_ = 0.3\n",
    "A = torch.ones(num_nodes,num_nodes,device='cpu')\n",
    "S,R = np.where(A==1)\n",
    "embeddings = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_cities):\n",
    "    x = torch.from_numpy(data_3d[i]).float()\n",
    "    model = GATE(hidden_dims,A,x,S,R)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0002)\n",
    "    for epoch in range(100):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss ,embedding,attention = model(A,x,R,S)\n",
    "        loss.backward()\n",
    "        # 在训练循环中添加梯度检查\n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.grad is None:\n",
    "        #         print(f\"参数 {name} 无梯度\")\n",
    "        #     else:\n",
    "        #         print(f\"参数 {param.shape} 梯度范数: {param.grad.norm().item():.4f},是否可训练{param.requires_grad}\")\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch{epoch}:Loss={loss.item():.4f}\")\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.stack(embeddings)\n",
    "print(data.shape)\n",
    "numpy_data = data.detach().numpy()\n",
    "numpy_data = numpy_data.reshape(292,110)\n",
    "print(numpy_data.shape)\n",
    "df = pd.DataFrame(numpy_data)\n",
    "df.to_excel('embedding.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_s = torch.tensor(numpy_data,dtype=torch.float32)\n",
    "model = GATEWithClustering(embedding_s)\n",
    "cluster_labels = model.cluster_cities()\n",
    "print(cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATEWithClustering():\n",
    "    def __init__(self,embeddings):\n",
    "        super().__init__()\n",
    "        self.cluster_labels = None\n",
    "        self.cluster_centers = None\n",
    "        self.lambda_ = 0.01\n",
    "        self.embeddings = embeddings\n",
    "    def cluster_cities(self,n_clusters = 3,visualize = True):\n",
    "        '''\n",
    "        城市韧性等级聚类(5类)\n",
    "        参数：\n",
    "          n_cluters:聚类数量（韧性等级数）\n",
    "          visualize:是否进行降维可视化\n",
    "        '''\n",
    "        #获取节点嵌入\n",
    "        X_emb =self.embeddings\n",
    "        \n",
    "        #使用KMeans聚类\n",
    "        kmeans = KMeans(n_clusters=n_clusters,random_state = 42,n_init=10)\n",
    "        self.cluster_labels = kmeans.fit_predict(X_emb)\n",
    "        self.cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "        #聚类结果分析\n",
    "        self._analyze_clusters()\n",
    "\n",
    "        #可视化嵌入空间\n",
    "        if visualize and X_emb.shape[1]>2:\n",
    "            self._visualize_embeddings(X_emb)\n",
    "\n",
    "        return self.cluster_labels\n",
    "    \n",
    "    def _analyze_clusters(self):\n",
    "        \"\"\"分析聚类结果\"\"\"\n",
    "        unique,counts = np.unique(self.cluster_labels,return_counts=True)\n",
    "        print(\"\\n城市韧性等级分布\")\n",
    "        for cls,cnt in zip(unique,counts):\n",
    "            print(f\"等级{cls+1}:{cnt}个城市(占比{cnt/len(self.cluster_labels):.1%})\")\n",
    "        #计算轮廓系数\n",
    "        from sklearn.metrics import silhouette_score\n",
    "        sil_score = silhouette_score(self.embeddings.detach().cpu().numpy(),self.cluster_labels)\n",
    "        print(f\"\\n轮廓系数:{sil_score:.3f}(越接近1表示聚类效果越好)\")\n",
    "\n",
    "    def _visualize_embeddings(self,X_emb,perplexity=2):\n",
    "        \"\"\"使用t-SNE降维可视化\"\"\"\n",
    "        tsne = TSNE(n_components=2,perplexity=perplexity,random_state=42)\n",
    "        X_tsne = tsne.fit_transform(X_emb)\n",
    "\n",
    "        plt.figure(figsize=(10,8))\n",
    "        scatter = plt.scatter(X_tsne[:,0],X_tsne[:,1],\n",
    "                              c = self.cluster_labels,\n",
    "                              cmap='viridis',\n",
    "                              alpha=0.7,\n",
    "                              edgecolors='w')\n",
    "        #添加图例和标签\n",
    "        plt.colorbar(scatter,ticks=range(5),label='韧性等级')\n",
    "        plt.title(\"城市韧性嵌入空间可视化(t-SNE)\")\n",
    "        plt.xlabel(\"t-SNE 1\")\n",
    "        plt.ylabel(\"t-SNE 2\")\n",
    "\n",
    "        #标记聚类中心\n",
    "        centers_tsne = tsne.fit_transform(self.cluster_centers)\n",
    "        plt.scatter(centers_tsne[:,0],centers_tsne[:,1],\n",
    "                    c='red',marker='X',s=200,\n",
    "                    edgecolors='k',linewidths=1.5,\n",
    "                    label='等级中心')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wuyu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
